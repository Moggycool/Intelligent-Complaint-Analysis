{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748f296a",
   "metadata": {},
   "source": [
    "# Embedding and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e379a",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Ensure project root is on sys.path so `src` imports work in the notebook\n",
    "sys.path.insert(0, str(Path.cwd().parent.resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vector_store import FaissVectorStore\n",
    "from src.embedding import EmbeddingModel\n",
    "from src.chunking import TextChunker\n",
    "from src.sampling import stratified_sample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfba5a2",
   "metadata": {},
   "source": [
    "# 2. Load Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93808de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve processed dataset path relative to project root\n",
    "PROJECT_ROOT = Path.cwd().parent.resolve()\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"filtered_complaints.csv\"\n",
    "print('Reading dataset from:', CSV_PATH)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"Consumer complaint narrative\": \"narrative\",\n",
    "    \"Product\": \"product\",\n",
    "    \"Complaint ID\": \"complaint_id\"\n",
    "})\n",
    "\n",
    "df.head()\n",
    "df[\"product\"].value_counts()\n",
    "df[\"product\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef67991",
   "metadata": {},
   "source": [
    "## 3 Stratified Sampling (10â€“15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2142395",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = stratified_sample(\n",
    "    df=df,\n",
    "    label_col=\"product\",\n",
    "    sample_size=12000\n",
    ")\n",
    "\n",
    "sampled_df[\"product\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab834353",
   "metadata": {},
   "source": [
    "## 4. Chunk Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd83e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = TextChunker(chunk_size=500, overlap=1)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for _, row in sampled_df.iterrows():\n",
    "    chunks = chunker.chunk(\n",
    "        text=row[\"narrative\"],\n",
    "        metadata={\n",
    "            \"complaint_id\": row[\"complaint_id\"],\n",
    "            \"product\": row[\"product\"]\n",
    "        }\n",
    "    )\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f3fc9",
   "metadata": {},
   "source": [
    "## 5. Prepare Texts + Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare texts + metadatas and filter out empty/whitespace-only texts\n",
    "pairs = [(c['text'], c['metadata']) for c in all_chunks]\n",
    "# Keep only pairs where text is a non-empty string after stripping\n",
    "filtered = [(t, m) for t, m in pairs if isinstance(t, str) and t.strip() != '']\n",
    "n_dropped = len(pairs) - len(filtered)\n",
    "if n_dropped > 0:\n",
    "    print(f'Filtered out {n_dropped} empty/whitespace-only chunks before embedding')\n",
    "texts = [t for t, _ in filtered]\n",
    "metadatas = [m for _, m in filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f2c7e",
   "metadata": {},
   "source": [
    "## 6. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5070d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = EmbeddingModel()\n",
    "embeddings = embedder.embed_texts(texts)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45779f",
   "metadata": {},
   "source": [
    "## 7. Build & Persist FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a681ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics: ensure embeddings and metadatas align\n",
    "import numpy as _np\n",
    "emb_shape = getattr(embeddings, 'shape', None)\n",
    "n_emb = int(emb_shape[0]) if emb_shape is not None else None\n",
    "n_meta = len(metadatas) if metadatas is not None else None\n",
    "print('embeddings.shape =', emb_shape)\n",
    "print('num metadatas =', n_meta)\n",
    "if n_emb != n_meta:\n",
    "    raise ValueError(f'Embeddings and metadata length mismatch: embeddings={n_emb}, metadatas={n_meta}')\n",
    "# Proceed to build and save the vector store\n",
    "vector_store = FaissVectorStore(embedding_dim=embeddings.shape[1])\n",
    "vector_store.add(embeddings, metadatas)\n",
    "vector_store.save(\"vector_store/faiss_index\")\n",
    "print(\"Vector store saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
